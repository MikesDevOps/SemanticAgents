@using Microsoft.Extensions.Options
@using SemanticAgents.Abstractions
@using SemanticAgents.Client.Abstractions
@using SemanticAgents.Configuration
@using SemanticAgents.SemanticKernelDTOs
@using System.Text.Json
@using System.Threading.Tasks

@* <h4>Local Model </h4> *@

@if (!string.IsNullOrWhiteSpace(_errorMessage))
{
    <p class="text-danger-alt m-2">@_errorMessage</p>
}
@if (!string.IsNullOrWhiteSpace(_warningMessage))
{
    <p class="text-warning-alt m-2">@_warningMessage</p>
}

@if (!_loadingConfiguration)
{
    <div class="row mt-2">
        <div class="col-2">
            <h5 class="mt-2">Loaded Model:</h5>
        </div>
        <div class="col-3">
            <input inert type="text" class="bg-dark text-light form-control mt-1" @bind-value="_loadedModelId" />
        </div>
        @if (_loadedLMStudioModel is not null)
        {
            <div class="col-2">
                <a class="btn button-custom-yellow form-control" @onclick="ShowLoadedLMStudioModel">Model Info</a>
            </div>
        }
    </div>

    <hr />
}


@if (_thinking)
{
    <div class="row mt-2">
        <div class="col-12">
            <p class="text-yellow-alt"><i>Validating LLM Configuration ...</i></p>
        </div>
    </div>
    <div class="mx-auto text-center mb-3 mt-3" style="height:160px;">
        <div class="spinner-border text-yellow-alt role-status">
            <span class="visually-hidden">Loading...</span>
        </div>
    </div>
}

@if (_showLMStudioModel && _loadedLMStudioModel is not null)
{
    <LoadedModelModal ModelDTO="_loadedLMStudioModel" ModalTitle="Loaded Model" Capabilities="@_loadedModelCapabilities"
        Cancel="HideLoadedLMStudioModel" CancelButtonTitle="Close" />
}

@code {

    [Parameter]
    public string? ConfiguredModelProvider { get; set; }
    [Inject]
    public ILMStudioHttpProvider? _lmStudioHttpProvider { get; set; }
    [Inject]
    public IOllamaHttpProvider? _ollamaHttpProvider { get; set; }
    [Inject]
    public IOptions<SemanticKernelSettings> _semanticKernelSettings { get; set; } = default!;
    [Inject]
    public IToastrService Toastr { get; set; } = default!;

    [Parameter]
    public EventCallback<string> ModelIdLoadedCallback { get; set; }

    private bool _loadingConfiguration;
    private bool _thinking;
    private string? _errorMessage;
    private string? _warningMessage;

    private string? _configuredTextModelId;
    private string? _loadedModelId;
    // private string? _modelInfo;

    private LMStudioModelDTO? _loadedLMStudioModel;
    private string? _loadedModelCapabilities;
    private bool _showLMStudioModel;
    private void ShowLoadedLMStudioModel()
    {
        if (_loadedLMStudioModel is null) return;
        // await Toastr.ShowToastrSuccess($"The loaded model is NOT null!!!");
        _showLMStudioModel = true;
    }
    private void HideLoadedLMStudioModel()
    {
        _showLMStudioModel = false;
    }

    private async Task GetLMStudioLoadedModelData()
    {
        try
        {
            // Get Text Model Id specified by configuration
            _configuredTextModelId = _semanticKernelSettings.Value.LMStudio_TextModelId;

            if (_lmStudioHttpProvider is null)
            {
                _errorMessage = $"The LMStudio Http Provider is null";
                return;
            }

            var result = await _lmStudioHttpProvider.GetLMStudioLoadedModelsAsync();
            if (result.IsSuccess)
            {
                List<LMStudioModelDTO>? loadedModels = result.LoadedModels?.ToList();
                if (loadedModels is not null && loadedModels.Any())
                {
                    _loadedLMStudioModel = loadedModels.FirstOrDefault(m => m.State == "loaded");
                    if (_loadedLMStudioModel is not null)
                    {
                        if (_loadedLMStudioModel.Capabilities is not null) _loadedModelCapabilities = string.Join(", ", _loadedLMStudioModel.Capabilities);
                        _loadedModelId = _loadedLMStudioModel.Id;

                        // await Toastr.ShowToastrSuccess($"LM Studio Model {_loadedModelId} is loaded.");
                        await ModelIdLoadedCallback.InvokeAsync(_loadedModelId);


                        if (_loadedModelId != _configuredTextModelId) _warningMessage = $"Warning: The actual text model \'{_loadedModelId}\' " +
                        $"loaded in LMStudio does not match the model \'{_configuredTextModelId}\' specified by the application configuration. " +
                        $"The model may not behave as expected.";
                    }
                    else
                    {
                        _errorMessage = "Please check LM Studio configuration.";
                    }
                }
            }
            else _errorMessage = result.ErrorMessage;
            _loadingConfiguration = false;
            _thinking = false;
        }
        catch (Exception ex)
        {
            _errorMessage = ex.Message;
        }
    }

    private async Task GetOllamaLoadedModelData()
    {
        // Get Text Model Id specified by configuration
        _configuredTextModelId = _semanticKernelSettings.Value.Ollama_TextModelId;

        // NOTE the list of models is not updated based on actual loaded models as not loading more than one model - only selected model is updated
        if (_ollamaHttpProvider is null)
        {
            _errorMessage = $"The Ollama Http Provider is null";
            return;
        }

        var result = await _ollamaHttpProvider.GetOllamaLoadedModelsAsync();
        if (result.IsSuccess)
        {
            List<OllamaModelDTO>? loadedModels = result.LoadedModels?.ToList();
            if (loadedModels is not null && loadedModels.Any())
            {
                OllamaModelDTO? loaded = loadedModels.FirstOrDefault();
                if (loaded is not null)
                {
                    _loadedModelId = loaded.Model;
                    
                    // await Toastr.ShowToastrSuccess($"Ollama Model {_loadedModelId} is loaded.");
                    await ModelIdLoadedCallback.InvokeAsync(_loadedModelId);

                    if (_loadedModelId != _configuredTextModelId) _warningMessage = $"Warning: The actual text model \'{_loadedModelId}\' " +
                    $"loaded in Ollama does not match the model \'{_configuredTextModelId}\' specified by the application configuration. " +
                    $"The model may not behave as expected.";
                }
                else
                {
                    _errorMessage = "Please check Ollama configuration. It may take a moment for the model query to respond.";
                }
            }
        }
        else _errorMessage = result.ErrorMessage;
        _loadingConfiguration = false;
        _thinking = false;
    }

    protected override async Task OnAfterRenderAsync(bool firstRender)
    {
        if (firstRender)
        {
            if (ConfiguredModelProvider == "LMStudio") await GetLMStudioLoadedModelData();
            else if (ConfiguredModelProvider == "Ollama") await GetOllamaLoadedModelData();
            
            StateHasChanged();
        }
    }

    protected override void OnInitialized()
    {
        _loadingConfiguration = true;
        _thinking = true;
    }
}