@page "/chat/basicChat"
@rendermode InteractiveServer
@using Microsoft.SemanticKernel
@using Microsoft.SemanticKernel.ChatCompletion
@using Microsoft.SemanticKernel.Connectors.OpenAI
@using SemanticAgents.Abstractions
@using SemanticAgents.Client.Abstractions
@using SemanticAgents.Configuration
@using SemanticAgents.SemanticKernelDTOs
@using SemanticAgents.SemanticKernelLocalHttpClients

<PageTitle>Basic Chat</PageTitle>

@if (_configuredModelProvider == "OpenAI" || _configuredModelProvider == "Grok")
{
    <RemoteModelConfiguration ConfiguredModelProvider="@_configuredModelProvider" ModelIsLoaded="SetModelIsLoaded"></RemoteModelConfiguration>
}
else if (_configuredModelProvider == "LMStudio" || _configuredModelProvider == "Ollama")
{
    <LocalModelConfiguration ConfiguredModelProvider="@_configuredModelProvider" ModelIsLoaded="SetModelIsLoaded"></LocalModelConfiguration>
}

@* BODY *@

<div class="row mt-2">
    @if (_modelIsLoaded)
    {
        <div class="col-2">
            @if (_chatHistory is null)
            {
                <a class="btn button-custom-primary form-control" @onclick="InitializeChat">Start Chat</a>
            }
            else
            {
                <a class="btn button-custom-primary form-control" @onclick="InitializeChat">Reset Chat</a>
            }
        </div>
        @if (_showReductionOption)
        {
            <div class="col-2 offset-4">
                <a class="btn button-custom-warning form-control" @onclick="ReduceChatHistory">Reduce History</a>
            </div>
            <div class="col-1">
                <p class="mt-2">Reduction:</p>
            </div>
            <div class="col-2 text-center">
                <select class="bg-dark text-light form-select mt-1" @bind="_reductionType">
                    @foreach (var type in _reductionTypesList)
                    {
                        <option value=@type>@type</option>
                    }
                </select>
            </div>
        }
    }
</div>

@if (_chatHistory is not null)
{
    <div class="row mt-2">
        <label for="userMessage" class="form-label">Your Message:</label>
        <textarea rows="4" class="bg-dark text-light form-control" id="userMessage" @bind="_userMessage" @onfocus="ClearUserMessage" " />
    </div>

    <div class="row mt-2">
        <div class="col-4 offset-4">
            <btn class="btn button-custom-success form-control" @onclick="SubmitUserMessage">Submit</btn>
        </div>
    </div>

    @if (_showChatHistory)
    {
        <div class="row mt-2">
            <label for="historyList" class="form-label">History:</label>
            <textarea rows="10" class="bg-dark text-light form-control" id="historyList" @bind="_messageHistoryList" />
        </div>
    }
    else
    {
        <div class="row mt-2">
            <label for="assistantMessage" class="form-label">Assistant Message:</label>
            <textarea rows="10" class="bg-dark text-light form-control" id="assistantMessage" @bind="_assistantMessage" />
        </div>
    }

    <div class="row mt-2">
        <div class="col-4 offset-4">
            <btn class="btn button-custom-success form-control" @onclick="ToggleShowChatHistory">@_showChatHistoryButtonText</btn>
        </div>
    </div>
}

@if (_thinking)
{
    <br />
    <div class="mx-auto text-center mb-3 mt-3">
        <div class="spinner-border text-yellow-alt role-status">
            <span class="visually-hidden">Loading...</span>
        </div>
    </div>
}

@code {

    [CascadingParameter(Name = "SemanticKernelInfo")]      // Root level cascading parameter
    private SemanticKernelInfo? _kernelInfo { get; set; }
    [Inject]
    private Kernel _kernel { get; set; } = default!;
    [Inject]
    private IToastrService _toastr { get; set; } = default!;
    [Inject]
    private ILMStudioHttpProvider _lmStudioHttpProvider { get; set; } = default!;
    [Inject]
    private IOllamaHttpProvider _ollamaHttpProvider { get; set; } = default!;

    private string? _configuredModelProvider;
    private bool _modelIsLoaded;

    private void SetModelIsLoaded(bool isLoaded) => _modelIsLoaded = isLoaded;

    private void ClearUserMessage() => _userMessage = string.Empty;
    private bool _showChatHistory;
    private string _showChatHistoryButtonText = "Show Chat History";
    private void ToggleShowChatHistory()
    {
        _showChatHistory = !_showChatHistory;
        if (_showChatHistory) _showChatHistoryButtonText = "Hide Chat History";
        else _showChatHistoryButtonText = "Show Chat History";
    }

    private OpenAIPromptExecutionSettings? _promptExecutionSettings;
    private ChatHistory? _chatHistory;
    private string? _userMessage;    // = string.Empty;
    private IChatCompletionService? _chatService;
    private string? _assistantMessage = string.Empty;
    private string? _messageHistoryList; // = string.Empty;
    private bool _thinking = false;
    private string? _errorMessage;
    private bool _showReductionOption;
    private int _reductionThreshold = 3;

    private void InitializeChat()
    {
        _promptExecutionSettings = new()
        {
            MaxTokens = 200,
            Temperature = 0.7,
            TopP = 0.95,
            FrequencyPenalty = 0,
            PresencePenalty = 0,
            ToolCallBehavior = ToolCallBehavior.AutoInvokeKernelFunctions
        };
        _chatHistory = new ChatHistory();
        _chatHistory.AddSystemMessage("You are a helpful assistant!");
        _userMessage = string.Empty;
        _assistantMessage = string.Empty;
        _messageHistoryList = string.Empty;
    }

    private async Task SubmitUserMessage()
    {
        if (!string.IsNullOrWhiteSpace(_userMessage))
        {
            _thinking = true;
            _chatHistory!.AddUserMessage(_userMessage);
            _messageHistoryList += $"USER: {_userMessage}\n\n";

            // // OPTION 1
            // ChatMessageContent assistantContent = await _chatService!.GetChatMessageContentAsync(_chatHistory!, _promptExecutionSettings, _kernel);
            // _messageHistoryList += ($"{assistantContent.Content}\n\n");
            // if (assistantContent.Content is not null) _chatHistory.AddAssistantMessage(assistantContent.Content);
            // _userMessage = string.Empty;

            // OPTION 2
            _assistantMessage = string.Empty;
            await foreach (StreamingChatMessageContent chunk in _chatService!.GetStreamingChatMessageContentsAsync(_chatHistory, _promptExecutionSettings, _kernel))
            {
                _assistantMessage += chunk.Content;
            }

            _messageHistoryList += ($"ASSISTANT: {_assistantMessage}\n\n");
            if (_assistantMessage is not null) _chatHistory.AddAssistantMessage(_assistantMessage);
            // _userMessage = string.Empty; // cleared with 'onfocus' event on element
            if (_chatHistory.Count >= _reductionThreshold) _showReductionOption = true;
            _thinking = false;
        }
        else await _toastr.ShowToastrError("Please enter a message.");
    }

    private List<string> _reductionTypesList = new List<string>() { "truncation", "summarization" };
    private string _reductionType = "truncation";
    private async Task ReduceChatHistory()
    {
        Console.WriteLine($"ReduceChatHistory called with reduction type {_reductionType}");

        if (_chatHistory is null)
        {
            _errorMessage = $"The ChatHistory is null.";
            return;
        }

        IChatHistoryReducer? reducer = null;
        if (_reductionType == "truncation")
        {
            reducer = new ChatHistoryTruncationReducer(2);
        }
        else if (_reductionType == "summarization")
        {
            if (_chatService is null)
            {
                _errorMessage = $"Cannot use Summarization to reduce chat history as the ChatService is null.";
                return;
            }
            reducer = new ChatHistorySummarizationReducer(_chatService, 2);
        }

        if (reducer is null)
        {
            _errorMessage = $"A ChatHistory Reducer was not properly configured.";
            return;
        }
        var reducedHistory = await reducer!.ReduceAsync(_chatHistory);
        if (reducedHistory is not null) 
        {
            _chatHistory = new ChatHistory(reducedHistory);
            _showReductionOption = false;
        }
    }

    protected override void OnInitialized()
    {
        if (_kernelInfo is not null) _configuredModelProvider = _kernelInfo.ModelProvider;
        _chatService = _kernel.GetRequiredService<IChatCompletionService>();
    }
}
